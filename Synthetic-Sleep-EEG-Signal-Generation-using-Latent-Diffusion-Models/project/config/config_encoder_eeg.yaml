train:
    seed: 2
    batch_size: 32  # Reduced from 16 for better stability
    n_epochs: 5000
    val_interval: 100
    num_workers: 10
    drop_last: false
    base_path: 'data/sleep-edfx'
    output_dir: '/project/outputs'
    run_dir: 'aekl_eeg_4channels_no_spec'  # Changed to indicate stability modifications
    experiment: 'AEKL'
models:
  optimizer_g_lr: 0.0001  # Reduced from 0.005 (50x lower) - critical for stability
  optimizer_d_lr: 0.00001 # Reduced from 0.0005 (50x lower) - critical for stability
  adv_weight: 0.005  # Reduced from 0.01 for more stable adversarial training
  kl_weight: 1E-6   # Increased from 1E-9 for better regularization
  spectral_weight: 1E1 # DRAMATICALLY reduced from 1E4 - this is the main source of NaNs

autoencoderkl:
  params:
    spatial_dims: 1
    in_channels: 19
    out_channels: 19
    num_channels: [4, 8, 16, 32]
    latent_channels: 4  # Increased from 1 to create a less constricted bottleneck
    num_res_blocks: 2
    norm_num_groups: 4  # Increased from 1 for better normalization
    attention_levels: [false, false, false, false]
    with_encoder_nonlocal_attn: false
    with_decoder_nonlocal_attn: false

patchdiscriminator:
  params:
    spatial_dims: 1
    num_layers_d: 3
    num_channels: 64
    in_channels: 19
    out_channels: 1
    kernel_size: 3
    norm: "BATCH"
    bias: false
    padding: 1